Authors
---------------------
Bryce Boe (bboe _at_ cs.ucsb.edu)
Christo Wilson (bowlin _at_ cs.ucsb.edu)


About
---------------------
CRAWL-E was designed to crawl the web fast fast as possible with as little
development time as possible. It is only a framework, and requires the
development of Handler modules inorder to function properly.


Installation
---------------------
Run: ./setup install
Note: You will probably need to be a root user to install the package.


Modules
---------------------
CRAWL-E contains two files: core.py and queue.py
    core.py  - This file contains all the core infrastructure to CRAWL-E, which
    	       is explained below.
    queue.py - This file contains the infrastructure to the locking queue which
	       utilizes the Pyro library. This class along with Pyro enables
	       CRAWL-E to easily handle get and put requests to the queue from
	       any number of machines.


The heart of CRAWL-E relies on extending the Crawle.core.Handler, in which one
must implement a process function. This function is where all the magic can
happen. We say can happen because it's entirely up to you what to do in this
function. Some possibilities are parsing links to add to the queue, simply
saving the contents of the page, or both!

To facilitate special needs one can extend Crawle.core.Auth. This class
contains functions which are called before every request. It can be utilized
to rate limit requests, handle authentication, and verify that fetched pages
are as expected to be.
